LD=3
Using: cuda
Train proportions: tensor([0.2509, 0.2442, 0.2506, 0.2543])
Test proportions: tensor([0.2463, 0.2732, 0.2476, 0.2329])
Epoch 1/500: train_loss: 1.1663 val_loss 0.9768
Saved at epoch 1.
Epoch 2/500: train_loss: 0.8316 val_loss 0.7148
Saved at epoch 2.
Epoch 3/500: train_loss: 0.6681 val_loss 0.6247
Saved at epoch 3.
Epoch 4/500: train_loss: 0.6106 val_loss 0.5751
Saved at epoch 4.
Epoch 5/500: train_loss: 0.5787 val_loss 0.5598
Saved at epoch 5.
Epoch 6/500: train_loss: 0.5606 val_loss 0.5336
Saved at epoch 6.
Epoch 7/500: train_loss: 0.5479 val_loss 0.5183
Saved at epoch 7.
Epoch 8/500: train_loss: 0.5353 val_loss 0.5086
Saved at epoch 8.
Epoch 9/500: train_loss: 0.5272 val_loss 0.4944
Saved at epoch 9.
Epoch 10/500: train_loss: 0.5178 val_loss 0.4897
Saved at epoch 10.
Epoch 11/500: train_loss: 0.5148 val_loss 0.4856
Saved at epoch 11.
Epoch 12/500: train_loss: 0.5088 val_loss 0.4809
Saved at epoch 12.
Epoch 13/500: train_loss: 0.5049 val_loss 0.4756
Saved at epoch 13.
Epoch 14/500: train_loss: 0.5033 val_loss 0.4728
Saved at epoch 14.
Epoch 15/500: train_loss: 0.4980 val_loss 0.4702
Saved at epoch 15.
Epoch 16/500: train_loss: 0.4957 val_loss 0.4694
Saved at epoch 16.
Epoch 17/500: train_loss: 0.4953 val_loss 0.4681
Saved at epoch 17.
Epoch 18/500: train_loss: 0.4947 val_loss 0.4658
Saved at epoch 18.
Epoch 19/500: train_loss: 0.4922 val_loss 0.4670
Epoch 20/500: train_loss: 0.4942 val_loss 0.4674
Epoch 21/500: train_loss: 0.4901 val_loss 0.4623
Saved at epoch 21.
Epoch 22/500: train_loss: 0.4869 val_loss 0.4607
Saved at epoch 22.
Epoch 23/500: train_loss: 0.4862 val_loss 0.4603
Saved at epoch 23.
Epoch 24/500: train_loss: 0.4844 val_loss 0.4593
Saved at epoch 24.
Epoch 25/500: train_loss: 0.4827 val_loss 0.4630
Epoch 26/500: train_loss: 0.4818 val_loss 0.4613
Epoch 27/500: train_loss: 0.4799 val_loss 0.4579
Saved at epoch 27.
Epoch 28/500: train_loss: 0.4806 val_loss 0.4553
Saved at epoch 28.
Epoch 29/500: train_loss: 0.4787 val_loss 0.4553
Saved at epoch 29.
Epoch 30/500: train_loss: 0.4775 val_loss 0.4563
Epoch 31/500: train_loss: 0.4770 val_loss 0.4540
Saved at epoch 31.
Epoch 32/500: train_loss: 0.4750 val_loss 0.4552
Epoch 33/500: train_loss: 0.4766 val_loss 0.4542
Epoch 34/500: train_loss: 0.4733 val_loss 0.4566
Epoch 35/500: train_loss: 0.4720 val_loss 0.4564
Epoch 36/500: train_loss: 0.4711 val_loss 0.4580
Epoch 37/500: train_loss: 0.4732 val_loss 0.4573
Epoch 38/500: train_loss: 0.4712 val_loss 0.4540
Saved at epoch 38.
Epoch 39/500: train_loss: 0.4686 val_loss 0.4516
Saved at epoch 39.
Epoch 40/500: train_loss: 0.4720 val_loss 0.4723
Epoch 41/500: train_loss: 0.4709 val_loss 0.4508
Saved at epoch 41.
Epoch 42/500: train_loss: 0.4663 val_loss 0.4509
Epoch 43/500: train_loss: 0.4702 val_loss 0.4537
Epoch 44/500: train_loss: 0.4690 val_loss 0.4513
Epoch 45/500: train_loss: 0.4658 val_loss 0.4567
Epoch 46/500: train_loss: 0.4651 val_loss 0.4531
Epoch 47/500: train_loss: 0.4636 val_loss 0.4577
Epoch 48/500: train_loss: 0.4651 val_loss 0.4518
Epoch 49/500: train_loss: 0.4638 val_loss 0.4518
Epoch 50/500: train_loss: 0.4605 val_loss 0.4552
Epoch 51/500: train_loss: 0.4633 val_loss 0.4562
Epoch 52/500: train_loss: 0.4608 val_loss 0.4697
Epoch 53/500: train_loss: 0.4606 val_loss 0.4535
Epoch 54/500: train_loss: 0.4593 val_loss 0.4608
Epoch 55/500: train_loss: 0.4605 val_loss 0.4506
Saved at epoch 55.
Epoch 56/500: train_loss: 0.4595 val_loss 0.4511
Epoch 57/500: train_loss: 0.4596 val_loss 0.4549
Epoch 58/500: train_loss: 0.4594 val_loss 0.4504
Saved at epoch 58.
Epoch 59/500: train_loss: 0.4576 val_loss 0.4499
Saved at epoch 59.
Epoch 60/500: train_loss: 0.4578 val_loss 0.4511
Epoch 61/500: train_loss: 0.4583 val_loss 0.4529
Epoch 62/500: train_loss: 0.4575 val_loss 0.4499
Saved at epoch 62.
Epoch 63/500: train_loss: 0.4583 val_loss 0.4510
Epoch 64/500: train_loss: 0.4569 val_loss 0.4499
Saved at epoch 64.
Epoch 65/500: train_loss: 0.4553 val_loss 0.4511
Epoch 66/500: train_loss: 0.4584 val_loss 0.4536
Epoch 67/500: train_loss: 0.4559 val_loss 0.4600
Epoch 68/500: train_loss: 0.4569 val_loss 0.4501
Epoch 69/500: train_loss: 0.4551 val_loss 0.4543
Epoch 70/500: train_loss: 0.4536 val_loss 0.4490
Saved at epoch 70.
Epoch 71/500: train_loss: 0.4565 val_loss 0.4502
Epoch 72/500: train_loss: 0.4557 val_loss 0.4583
Epoch 73/500: train_loss: 0.4529 val_loss 0.4525
Epoch 74/500: train_loss: 0.4569 val_loss 0.4563
Epoch 75/500: train_loss: 0.4520 val_loss 0.4512
Epoch 76/500: train_loss: 0.4506 val_loss 0.4551
Epoch 77/500: train_loss: 0.4532 val_loss 0.4511
Epoch 78/500: train_loss: 0.4510 val_loss 0.4539
Epoch 79/500: train_loss: 0.4534 val_loss 0.4522
Epoch 80/500: train_loss: 0.4518 val_loss 0.4520
Epoch 81/500: train_loss: 0.4497 val_loss 0.4552
Epoch 82/500: train_loss: 0.4522 val_loss 0.4527
Epoch 83/500: train_loss: 0.4508 val_loss 0.4591
Epoch 84/500: train_loss: 0.4546 val_loss 0.4583
Epoch 85/500: train_loss: 0.4520 val_loss 0.4504
Epoch 86/500: train_loss: 0.4490 val_loss 0.4535
Epoch 87/500: train_loss: 0.4523 val_loss 0.4527
Epoch 88/500: train_loss: 0.4529 val_loss 0.4529
Epoch 89/500: train_loss: 0.4498 val_loss 0.4512
Epoch 90/500: train_loss: 0.4483 val_loss 0.4518
Epoch 91/500: train_loss: 0.4507 val_loss 0.4568
Epoch 92/500: train_loss: 0.4499 val_loss 0.4570
Epoch 93/500: train_loss: 0.4497 val_loss 0.4606
Epoch 94/500: train_loss: 0.4510 val_loss 0.4513
Epoch 95/500: train_loss: 0.4499 val_loss 0.4559
Epoch 96/500: train_loss: 0.4510 val_loss 0.4533
Epoch 97/500: train_loss: 0.4497 val_loss 0.4506
Epoch 98/500: train_loss: 0.4504 val_loss 0.4569
Epoch 99/500: train_loss: 0.4477 val_loss 0.4515
Epoch 100/500: train_loss: 0.4486 val_loss 0.4733
Epoch 101/500: train_loss: 0.4505 val_loss 0.4518
Epoch 102/500: train_loss: 0.4468 val_loss 0.4514
Epoch 103/500: train_loss: 0.4477 val_loss 0.4692
Epoch 104/500: train_loss: 0.4469 val_loss 0.4553
Epoch 105/500: train_loss: 0.4489 val_loss 0.4543
Epoch 106/500: train_loss: 0.4471 val_loss 0.4534
Epoch 107/500: train_loss: 0.4465 val_loss 0.4521
Epoch 108/500: train_loss: 0.4461 val_loss 0.4508
Epoch 109/500: train_loss: 0.4453 val_loss 0.4499
Epoch 110/500: train_loss: 0.4474 val_loss 0.4509
Epoch 111/500: train_loss: 0.4464 val_loss 0.4548
Epoch 112/500: train_loss: 0.4471 val_loss 0.4560
Epoch 113/500: train_loss: 0.4452 val_loss 0.4503
Epoch 114/500: train_loss: 0.4451 val_loss 0.4722
Epoch 115/500: train_loss: 0.4464 val_loss 0.4503
Epoch 116/500: train_loss: 0.4462 val_loss 0.4607
Epoch 117/500: train_loss: 0.4460 val_loss 0.4645
Epoch 118/500: train_loss: 0.4464 val_loss 0.4524
Epoch 119/500: train_loss: 0.4449 val_loss 0.4489
Saved at epoch 119.
Epoch 120/500: train_loss: 0.4501 val_loss 0.4581
Epoch 121/500: train_loss: 0.4454 val_loss 0.4553
Epoch 122/500: train_loss: 0.4434 val_loss 0.4519
Epoch 123/500: train_loss: 0.4469 val_loss 0.4508
Epoch 124/500: train_loss: 0.4433 val_loss 0.4580
Epoch 125/500: train_loss: 0.4446 val_loss 0.4506
Epoch 126/500: train_loss: 0.4465 val_loss 0.4513
Epoch 127/500: train_loss: 0.4429 val_loss 0.4525
Epoch 128/500: train_loss: 0.4440 val_loss 0.4542
Epoch 129/500: train_loss: 0.4460 val_loss 0.4512
Epoch 130/500: train_loss: 0.4456 val_loss 0.4558
Epoch 131/500: train_loss: 0.4440 val_loss 0.4506
Epoch 132/500: train_loss: 0.4461 val_loss 0.4508
Epoch 133/500: train_loss: 0.4422 val_loss 0.4586
Epoch 134/500: train_loss: 0.4414 val_loss 0.4504
Epoch 135/500: train_loss: 0.4426 val_loss 0.4596
Epoch 136/500: train_loss: 0.4450 val_loss 0.4552
Epoch 137/500: train_loss: 0.4439 val_loss 0.4668
Epoch 138/500: train_loss: 0.4428 val_loss 0.4511
Epoch 139/500: train_loss: 0.4420 val_loss 0.4548
Epoch 140/500: train_loss: 0.4423 val_loss 0.4529
Epoch 141/500: train_loss: 0.4426 val_loss 0.4528
Epoch 142/500: train_loss: 0.4428 val_loss 0.4516
Epoch 143/500: train_loss: 0.4410 val_loss 0.4534
Epoch 144/500: train_loss: 0.4415 val_loss 0.4569
Epoch 145/500: train_loss: 0.4417 val_loss 0.4496
Epoch 146/500: train_loss: 0.4421 val_loss 0.4504
Epoch 147/500: train_loss: 0.4445 val_loss 0.4516
Epoch 148/500: train_loss: 0.4419 val_loss 0.4527
Epoch 149/500: train_loss: 0.4427 val_loss 0.4497
Epoch 150/500: train_loss: 0.4398 val_loss 0.4516
Epoch 151/500: train_loss: 0.4416 val_loss 0.4513
Epoch 152/500: train_loss: 0.4436 val_loss 0.4487
Saved at epoch 152.
Epoch 153/500: train_loss: 0.4402 val_loss 0.4538
Epoch 154/500: train_loss: 0.4406 val_loss 0.4517
Epoch 155/500: train_loss: 0.4400 val_loss 0.4523
Epoch 156/500: train_loss: 0.4397 val_loss 0.4502
Epoch 157/500: train_loss: 0.4401 val_loss 0.4505
Epoch 158/500: train_loss: 0.4409 val_loss 0.4508
Epoch 159/500: train_loss: 0.4390 val_loss 0.4538
Epoch 160/500: train_loss: 0.4419 val_loss 0.4501
Epoch 161/500: train_loss: 0.4395 val_loss 0.4518
Epoch 162/500: train_loss: 0.4392 val_loss 0.4512
Epoch 163/500: train_loss: 0.4414 val_loss 0.4511
Epoch 164/500: train_loss: 0.4420 val_loss 0.4519
Epoch 165/500: train_loss: 0.4401 val_loss 0.4577
Epoch 166/500: train_loss: 0.4413 val_loss 0.4490
Epoch 167/500: train_loss: 0.4401 val_loss 0.4585
Epoch 168/500: train_loss: 0.4395 val_loss 0.4494
Epoch 169/500: train_loss: 0.4383 val_loss 0.4494
Epoch 170/500: train_loss: 0.4385 val_loss 0.4496
Epoch 171/500: train_loss: 0.4419 val_loss 0.4511
Epoch 172/500: train_loss: 0.4400 val_loss 0.4491
Epoch 173/500: train_loss: 0.4398 val_loss 0.4514
Epoch 174/500: train_loss: 0.4394 val_loss 0.4510
Epoch 175/500: train_loss: 0.4376 val_loss 0.4493
Epoch 176/500: train_loss: 0.4367 val_loss 0.4530
Epoch 177/500: train_loss: 0.4385 val_loss 0.4572
Epoch 178/500: train_loss: 0.4384 val_loss 0.4525
Epoch 179/500: train_loss: 0.4390 val_loss 0.4520
Epoch 180/500: train_loss: 0.4408 val_loss 0.4505
Epoch 181/500: train_loss: 0.4378 val_loss 0.4486
Saved at epoch 181.
Epoch 182/500: train_loss: 0.4387 val_loss 0.4509
Epoch 183/500: train_loss: 0.4394 val_loss 0.4498
Epoch 184/500: train_loss: 0.4387 val_loss 0.4494
Epoch 185/500: train_loss: 0.4393 val_loss 0.4515
Epoch 186/500: train_loss: 0.4384 val_loss 0.4498
Epoch 187/500: train_loss: 0.4368 val_loss 0.4554
Epoch 188/500: train_loss: 0.4368 val_loss 0.4501
Epoch 189/500: train_loss: 0.4400 val_loss 0.4495
Epoch 190/500: train_loss: 0.4379 val_loss 0.4566
Epoch 191/500: train_loss: 0.4410 val_loss 0.4500
Epoch 192/500: train_loss: 0.4382 val_loss 0.4501
Epoch 193/500: train_loss: 0.4367 val_loss 0.4495
Epoch 194/500: train_loss: 0.4357 val_loss 0.4712
Epoch 195/500: train_loss: 0.4401 val_loss 0.4620
Epoch 196/500: train_loss: 0.4389 val_loss 0.4552
Epoch 197/500: train_loss: 0.4376 val_loss 0.4517
Epoch 198/500: train_loss: 0.4366 val_loss 0.4505
Epoch 199/500: train_loss: 0.4352 val_loss 0.4599
Epoch 200/500: train_loss: 0.4382 val_loss 0.4478
Saved at epoch 200.
Epoch 201/500: train_loss: 0.4359 val_loss 0.4528
Epoch 202/500: train_loss: 0.4362 val_loss 0.4492
Epoch 203/500: train_loss: 0.4382 val_loss 0.4508
Epoch 204/500: train_loss: 0.4366 val_loss 0.4516
Epoch 205/500: train_loss: 0.4370 val_loss 0.4533
Epoch 206/500: train_loss: 0.4366 val_loss 0.4497
Epoch 207/500: train_loss: 0.4366 val_loss 0.4498
Epoch 208/500: train_loss: 0.4364 val_loss 0.4492
Epoch 209/500: train_loss: 0.4395 val_loss 0.4500
Epoch 210/500: train_loss: 0.4376 val_loss 0.4486
Epoch 211/500: train_loss: 0.4356 val_loss 0.4499
Epoch 212/500: train_loss: 0.4356 val_loss 0.4495
Epoch 213/500: train_loss: 0.4366 val_loss 0.4489
Epoch 214/500: train_loss: 0.4356 val_loss 0.4527
Epoch 215/500: train_loss: 0.4350 val_loss 0.4629
Epoch 216/500: train_loss: 0.4373 val_loss 0.4512
Epoch 217/500: train_loss: 0.4356 val_loss 0.4551
Epoch 218/500: train_loss: 0.4348 val_loss 0.4510
Epoch 219/500: train_loss: 0.4348 val_loss 0.4486
Epoch 220/500: train_loss: 0.4368 val_loss 0.4495
Epoch 221/500: train_loss: 0.4427 val_loss 0.4509
Epoch 222/500: train_loss: 0.4370 val_loss 0.4503
Epoch 223/500: train_loss: 0.4353 val_loss 0.4597
Epoch 224/500: train_loss: 0.4350 val_loss 0.4516
Epoch 225/500: train_loss: 0.4349 val_loss 0.4504
Epoch 226/500: train_loss: 0.4341 val_loss 0.4598
Epoch 227/500: train_loss: 0.4354 val_loss 0.4496
Epoch 228/500: train_loss: 0.4350 val_loss 0.4509
Epoch 229/500: train_loss: 0.4346 val_loss 0.4510
Epoch 230/500: train_loss: 0.4367 val_loss 0.4517
Epoch 231/500: train_loss: 0.4371 val_loss 0.4521
Epoch 232/500: train_loss: 0.4356 val_loss 0.4527
Epoch 233/500: train_loss: 0.4356 val_loss 0.4536
Epoch 234/500: train_loss: 0.4340 val_loss 0.4515
Epoch 235/500: train_loss: 0.4340 val_loss 0.4508
Epoch 236/500: train_loss: 0.4335 val_loss 0.4501
Epoch 237/500: train_loss: 0.4346 val_loss 0.4500
Epoch 238/500: train_loss: 0.4353 val_loss 0.4530
Epoch 239/500: train_loss: 0.4356 val_loss 0.4513
Epoch 240/500: train_loss: 0.4346 val_loss 0.4543
Epoch 241/500: train_loss: 0.4379 val_loss 0.4563
Epoch 242/500: train_loss: 0.4343 val_loss 0.4522
Epoch 243/500: train_loss: 0.4350 val_loss 0.4560
Epoch 244/500: train_loss: 0.4412 val_loss 0.4585
Epoch 245/500: train_loss: 0.4369 val_loss 0.4511
Epoch 246/500: train_loss: 0.4346 val_loss 0.4510
Epoch 247/500: train_loss: 0.4343 val_loss 0.4517
Epoch 248/500: train_loss: 0.4358 val_loss 0.4554
Epoch 249/500: train_loss: 0.4345 val_loss 0.4520
Epoch 250/500: train_loss: 0.4347 val_loss 0.4506
Early stopping at epoch 250.
Test Accuracy: 95.85%
